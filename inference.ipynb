{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the validation set with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T13:51:53.180424Z",
     "start_time": "2020-06-11T13:51:48.951064Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from medpy.filter.binary import largest_connected_component\n",
    "from skimage.io import imsave\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import BrainSegmentationDataset as Dataset\n",
    "from unet import UNet\n",
    "from utils import dsc, gray2rgb, outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T13:51:53.211553Z",
     "start_time": "2020-06-11T13:51:53.183003Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_loader(args):\n",
    "    dataset = Dataset(\n",
    "        images_dir=args.images,\n",
    "        subset=\"validation\",\n",
    "        image_size=args.image_size,\n",
    "        random_sampling=False,\n",
    "    )\n",
    "    loader = DataLoader(\n",
    "        dataset, batch_size=args.batch_size, drop_last=False, num_workers=1\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "def postprocess_per_volume(\n",
    "    input_list, pred_list, true_list, patient_slice_index, patients\n",
    "):\n",
    "    volumes = {}\n",
    "    num_slices = np.bincount([p[0] for p in patient_slice_index])\n",
    "    index = 0\n",
    "    for p in range(len(num_slices)):\n",
    "        volume_in = np.array(input_list[index : index + num_slices[p]])\n",
    "        volume_pred = np.round(\n",
    "            np.array(pred_list[index : index + num_slices[p]])\n",
    "        ).astype(int)\n",
    "        volume_pred = largest_connected_component(volume_pred)\n",
    "        volume_true = np.array(true_list[index : index + num_slices[p]])\n",
    "        volumes[patients[p]] = (volume_in, volume_pred, volume_true)\n",
    "        index += num_slices[p]\n",
    "    return volumes\n",
    "\n",
    "\n",
    "def dsc_distribution(volumes):\n",
    "    dsc_dict = {}\n",
    "    for p in volumes:\n",
    "        y_pred = volumes[p][1]\n",
    "        y_true = volumes[p][2]\n",
    "        dsc_dict[p] = dsc(y_pred, y_true, lcc=False)\n",
    "    return dsc_dict\n",
    "\n",
    "\n",
    "def plot_dsc(dsc_dist):\n",
    "    y_positions = np.arange(len(dsc_dist))\n",
    "    dsc_dist = sorted(dsc_dist.items(), key=lambda x: x[1])\n",
    "    values = [x[1] for x in dsc_dist]\n",
    "    labels = [x[0] for x in dsc_dist]\n",
    "    labels = [\"_\".join(l.split(\"_\")[1:-1]) for l in labels]\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    plt.barh(y_positions, values, align=\"center\", color=\"skyblue\")\n",
    "    plt.yticks(y_positions, labels)\n",
    "    plt.xticks(np.arange(0.0, 1.0, 0.1))\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.gca().axvline(np.mean(values), color=\"tomato\", linewidth=2)\n",
    "    plt.gca().axvline(np.median(values), color=\"forestgreen\", linewidth=2)\n",
    "    plt.xlabel(\"Dice coefficient\", fontsize=\"x-large\")\n",
    "    plt.gca().xaxis.grid(color=\"silver\", alpha=0.5, linestyle=\"--\", linewidth=1)\n",
    "    plt.tight_layout()\n",
    "    canvas.draw()\n",
    "    plt.close()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "    return np.frombuffer(s, np.uint8).reshape((height, width, 4))\n",
    "\n",
    "\n",
    "def makedirs(args):\n",
    "    os.makedirs(args.predictions, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    device = 'cuda:0'\n",
    "    batch_size = 32\n",
    "    weights = './weights/unet.pt'\n",
    "    images = './BrainMRI/kaggle_3m'\n",
    "    image_size = 256\n",
    "    predictions = './predictions'\n",
    "    figure = './dsc.png'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T13:51:53.256508Z",
     "start_time": "2020-06-11T13:51:53.214026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading validation images...\n",
      "Load dataset from cache: .cache\\validation.pkl\n",
      "done creating validation dataset\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"downs.0.0.weight\", \"downs.0.1.weight\", \"downs.0.1.bias\", \"downs.0.1.running_mean\", \"downs.0.1.running_var\", \"downs.0.3.weight\", \"downs.0.4.weight\", \"downs.0.4.bias\", \"downs.0.4.running_mean\", \"downs.0.4.running_var\", \"downs.1.0.weight\", \"downs.1.1.weight\", \"downs.1.1.bias\", \"downs.1.1.running_mean\", \"downs.1.1.running_var\", \"downs.1.3.weight\", \"downs.1.4.weight\", \"downs.1.4.bias\", \"downs.1.4.running_mean\", \"downs.1.4.running_var\", \"downs.2.0.weight\", \"downs.2.1.weight\", \"downs.2.1.bias\", \"downs.2.1.running_mean\", \"downs.2.1.running_var\", \"downs.2.3.weight\", \"downs.2.4.weight\", \"downs.2.4.bias\", \"downs.2.4.running_mean\", \"downs.2.4.running_var\", \"downs.3.0.weight\", \"downs.3.1.weight\", \"downs.3.1.bias\", \"downs.3.1.running_mean\", \"downs.3.1.running_var\", \"downs.3.3.weight\", \"downs.3.4.weight\", \"downs.3.4.bias\", \"downs.3.4.running_mean\", \"downs.3.4.running_var\", \"ups.0.weight\", \"ups.0.bias\", \"ups.1.weight\", \"ups.1.bias\", \"ups.2.weight\", \"ups.2.bias\", \"ups.3.weight\", \"ups.3.bias\", \"up_convs.0.0.weight\", \"up_convs.0.1.weight\", \"up_convs.0.1.bias\", \"up_convs.0.1.running_mean\", \"up_convs.0.1.running_var\", \"up_convs.0.3.weight\", \"up_convs.0.4.weight\", \"up_convs.0.4.bias\", \"up_convs.0.4.running_mean\", \"up_convs.0.4.running_var\", \"up_convs.1.0.weight\", \"up_convs.1.1.weight\", \"up_convs.1.1.bias\", \"up_convs.1.1.running_mean\", \"up_convs.1.1.running_var\", \"up_convs.1.3.weight\", \"up_convs.1.4.weight\", \"up_convs.1.4.bias\", \"up_convs.1.4.running_mean\", \"up_convs.1.4.running_var\", \"up_convs.2.0.weight\", \"up_convs.2.1.weight\", \"up_convs.2.1.bias\", \"up_convs.2.1.running_mean\", \"up_convs.2.1.running_var\", \"up_convs.2.3.weight\", \"up_convs.2.4.weight\", \"up_convs.2.4.bias\", \"up_convs.2.4.running_mean\", \"up_convs.2.4.running_var\", \"up_convs.3.0.weight\", \"up_convs.3.1.weight\", \"up_convs.3.1.bias\", \"up_convs.3.1.running_mean\", \"up_convs.3.1.running_var\", \"up_convs.3.3.weight\", \"up_convs.3.4.weight\", \"up_convs.3.4.bias\", \"up_convs.3.4.running_mean\", \"up_convs.3.4.running_var\", \"final.weight\", \"final.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.0.0.weight\", \"encoder.0.1.weight\", \"encoder.0.1.bias\", \"encoder.0.1.running_mean\", \"encoder.0.1.running_var\", \"encoder.0.1.num_batches_tracked\", \"encoder.0.3.weight\", \"encoder.0.4.weight\", \"encoder.0.4.bias\", \"encoder.0.4.running_mean\", \"encoder.0.4.running_var\", \"encoder.0.4.num_batches_tracked\", \"encoder.1.0.weight\", \"encoder.1.1.weight\", \"encoder.1.1.bias\", \"encoder.1.1.running_mean\", \"encoder.1.1.running_var\", \"encoder.1.1.num_batches_tracked\", \"encoder.1.3.weight\", \"encoder.1.4.weight\", \"encoder.1.4.bias\", \"encoder.1.4.running_mean\", \"encoder.1.4.running_var\", \"encoder.1.4.num_batches_tracked\", \"encoder.2.0.weight\", \"encoder.2.1.weight\", \"encoder.2.1.bias\", \"encoder.2.1.running_mean\", \"encoder.2.1.running_var\", \"encoder.2.1.num_batches_tracked\", \"encoder.2.3.weight\", \"encoder.2.4.weight\", \"encoder.2.4.bias\", \"encoder.2.4.running_mean\", \"encoder.2.4.running_var\", \"encoder.2.4.num_batches_tracked\", \"encoder.3.0.weight\", \"encoder.3.1.weight\", \"encoder.3.1.bias\", \"encoder.3.1.running_mean\", \"encoder.3.1.running_var\", \"encoder.3.1.num_batches_tracked\", \"encoder.3.3.weight\", \"encoder.3.4.weight\", \"encoder.3.4.bias\", \"encoder.3.4.running_mean\", \"encoder.3.4.running_var\", \"encoder.3.4.num_batches_tracked\", \"decoder.0.weight\", \"decoder.0.bias\", \"decoder.1.0.weight\", \"decoder.1.1.weight\", \"decoder.1.1.bias\", \"decoder.1.1.running_mean\", \"decoder.1.1.running_var\", \"decoder.1.1.num_batches_tracked\", \"decoder.1.3.weight\", \"decoder.1.4.weight\", \"decoder.1.4.bias\", \"decoder.1.4.running_mean\", \"decoder.1.4.running_var\", \"decoder.1.4.num_batches_tracked\", \"decoder.2.weight\", \"decoder.2.bias\", \"decoder.3.0.weight\", \"decoder.3.1.weight\", \"decoder.3.1.bias\", \"decoder.3.1.running_mean\", \"decoder.3.1.running_var\", \"decoder.3.1.num_batches_tracked\", \"decoder.3.3.weight\", \"decoder.3.4.weight\", \"decoder.3.4.bias\", \"decoder.3.4.running_mean\", \"decoder.3.4.running_var\", \"decoder.3.4.num_batches_tracked\", \"decoder.4.weight\", \"decoder.4.bias\", \"decoder.5.0.weight\", \"decoder.5.1.weight\", \"decoder.5.1.bias\", \"decoder.5.1.running_mean\", \"decoder.5.1.running_var\", \"decoder.5.1.num_batches_tracked\", \"decoder.5.3.weight\", \"decoder.5.4.weight\", \"decoder.5.4.bias\", \"decoder.5.4.running_mean\", \"decoder.5.4.running_var\", \"decoder.5.4.num_batches_tracked\", \"decoder.6.weight\", \"decoder.6.bias\", \"decoder.7.0.weight\", \"decoder.7.1.weight\", \"decoder.7.1.bias\", \"decoder.7.1.running_mean\", \"decoder.7.1.running_var\", \"decoder.7.1.num_batches_tracked\", \"decoder.7.3.weight\", \"decoder.7.4.weight\", \"decoder.7.4.bias\", \"decoder.7.4.running_mean\", \"decoder.7.4.running_var\", \"decoder.7.4.num_batches_tracked\", \"final_conv.weight\", \"final_conv.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m unet = UNet(in_channels=Dataset.in_channels, out_channels=Dataset.out_channels)\n\u001b[32m     10\u001b[39m state_dict = torch.load(args.weights, map_location=device)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43munet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m unet.eval()\n\u001b[32m     13\u001b[39m unet.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\louis\\thu\\DL_Project_1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2581\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2573\u001b[39m         error_msgs.insert(\n\u001b[32m   2574\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2575\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2576\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2577\u001b[39m             ),\n\u001b[32m   2578\u001b[39m         )\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2583\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2584\u001b[39m         )\n\u001b[32m   2585\u001b[39m     )\n\u001b[32m   2586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"downs.0.0.weight\", \"downs.0.1.weight\", \"downs.0.1.bias\", \"downs.0.1.running_mean\", \"downs.0.1.running_var\", \"downs.0.3.weight\", \"downs.0.4.weight\", \"downs.0.4.bias\", \"downs.0.4.running_mean\", \"downs.0.4.running_var\", \"downs.1.0.weight\", \"downs.1.1.weight\", \"downs.1.1.bias\", \"downs.1.1.running_mean\", \"downs.1.1.running_var\", \"downs.1.3.weight\", \"downs.1.4.weight\", \"downs.1.4.bias\", \"downs.1.4.running_mean\", \"downs.1.4.running_var\", \"downs.2.0.weight\", \"downs.2.1.weight\", \"downs.2.1.bias\", \"downs.2.1.running_mean\", \"downs.2.1.running_var\", \"downs.2.3.weight\", \"downs.2.4.weight\", \"downs.2.4.bias\", \"downs.2.4.running_mean\", \"downs.2.4.running_var\", \"downs.3.0.weight\", \"downs.3.1.weight\", \"downs.3.1.bias\", \"downs.3.1.running_mean\", \"downs.3.1.running_var\", \"downs.3.3.weight\", \"downs.3.4.weight\", \"downs.3.4.bias\", \"downs.3.4.running_mean\", \"downs.3.4.running_var\", \"ups.0.weight\", \"ups.0.bias\", \"ups.1.weight\", \"ups.1.bias\", \"ups.2.weight\", \"ups.2.bias\", \"ups.3.weight\", \"ups.3.bias\", \"up_convs.0.0.weight\", \"up_convs.0.1.weight\", \"up_convs.0.1.bias\", \"up_convs.0.1.running_mean\", \"up_convs.0.1.running_var\", \"up_convs.0.3.weight\", \"up_convs.0.4.weight\", \"up_convs.0.4.bias\", \"up_convs.0.4.running_mean\", \"up_convs.0.4.running_var\", \"up_convs.1.0.weight\", \"up_convs.1.1.weight\", \"up_convs.1.1.bias\", \"up_convs.1.1.running_mean\", \"up_convs.1.1.running_var\", \"up_convs.1.3.weight\", \"up_convs.1.4.weight\", \"up_convs.1.4.bias\", \"up_convs.1.4.running_mean\", \"up_convs.1.4.running_var\", \"up_convs.2.0.weight\", \"up_convs.2.1.weight\", \"up_convs.2.1.bias\", \"up_convs.2.1.running_mean\", \"up_convs.2.1.running_var\", \"up_convs.2.3.weight\", \"up_convs.2.4.weight\", \"up_convs.2.4.bias\", \"up_convs.2.4.running_mean\", \"up_convs.2.4.running_var\", \"up_convs.3.0.weight\", \"up_convs.3.1.weight\", \"up_convs.3.1.bias\", \"up_convs.3.1.running_mean\", \"up_convs.3.1.running_var\", \"up_convs.3.3.weight\", \"up_convs.3.4.weight\", \"up_convs.3.4.bias\", \"up_convs.3.4.running_mean\", \"up_convs.3.4.running_var\", \"final.weight\", \"final.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.0.0.weight\", \"encoder.0.1.weight\", \"encoder.0.1.bias\", \"encoder.0.1.running_mean\", \"encoder.0.1.running_var\", \"encoder.0.1.num_batches_tracked\", \"encoder.0.3.weight\", \"encoder.0.4.weight\", \"encoder.0.4.bias\", \"encoder.0.4.running_mean\", \"encoder.0.4.running_var\", \"encoder.0.4.num_batches_tracked\", \"encoder.1.0.weight\", \"encoder.1.1.weight\", \"encoder.1.1.bias\", \"encoder.1.1.running_mean\", \"encoder.1.1.running_var\", \"encoder.1.1.num_batches_tracked\", \"encoder.1.3.weight\", \"encoder.1.4.weight\", \"encoder.1.4.bias\", \"encoder.1.4.running_mean\", \"encoder.1.4.running_var\", \"encoder.1.4.num_batches_tracked\", \"encoder.2.0.weight\", \"encoder.2.1.weight\", \"encoder.2.1.bias\", \"encoder.2.1.running_mean\", \"encoder.2.1.running_var\", \"encoder.2.1.num_batches_tracked\", \"encoder.2.3.weight\", \"encoder.2.4.weight\", \"encoder.2.4.bias\", \"encoder.2.4.running_mean\", \"encoder.2.4.running_var\", \"encoder.2.4.num_batches_tracked\", \"encoder.3.0.weight\", \"encoder.3.1.weight\", \"encoder.3.1.bias\", \"encoder.3.1.running_mean\", \"encoder.3.1.running_var\", \"encoder.3.1.num_batches_tracked\", \"encoder.3.3.weight\", \"encoder.3.4.weight\", \"encoder.3.4.bias\", \"encoder.3.4.running_mean\", \"encoder.3.4.running_var\", \"encoder.3.4.num_batches_tracked\", \"decoder.0.weight\", \"decoder.0.bias\", \"decoder.1.0.weight\", \"decoder.1.1.weight\", \"decoder.1.1.bias\", \"decoder.1.1.running_mean\", \"decoder.1.1.running_var\", \"decoder.1.1.num_batches_tracked\", \"decoder.1.3.weight\", \"decoder.1.4.weight\", \"decoder.1.4.bias\", \"decoder.1.4.running_mean\", \"decoder.1.4.running_var\", \"decoder.1.4.num_batches_tracked\", \"decoder.2.weight\", \"decoder.2.bias\", \"decoder.3.0.weight\", \"decoder.3.1.weight\", \"decoder.3.1.bias\", \"decoder.3.1.running_mean\", \"decoder.3.1.running_var\", \"decoder.3.1.num_batches_tracked\", \"decoder.3.3.weight\", \"decoder.3.4.weight\", \"decoder.3.4.bias\", \"decoder.3.4.running_mean\", \"decoder.3.4.running_var\", \"decoder.3.4.num_batches_tracked\", \"decoder.4.weight\", \"decoder.4.bias\", \"decoder.5.0.weight\", \"decoder.5.1.weight\", \"decoder.5.1.bias\", \"decoder.5.1.running_mean\", \"decoder.5.1.running_var\", \"decoder.5.1.num_batches_tracked\", \"decoder.5.3.weight\", \"decoder.5.4.weight\", \"decoder.5.4.bias\", \"decoder.5.4.running_mean\", \"decoder.5.4.running_var\", \"decoder.5.4.num_batches_tracked\", \"decoder.6.weight\", \"decoder.6.bias\", \"decoder.7.0.weight\", \"decoder.7.1.weight\", \"decoder.7.1.bias\", \"decoder.7.1.running_mean\", \"decoder.7.1.running_var\", \"decoder.7.1.num_batches_tracked\", \"decoder.7.3.weight\", \"decoder.7.4.weight\", \"decoder.7.4.bias\", \"decoder.7.4.running_mean\", \"decoder.7.4.running_var\", \"decoder.7.4.num_batches_tracked\", \"final_conv.weight\", \"final_conv.bias\". "
     ]
    }
   ],
   "source": [
    "assert osp.exists(args.images), \"Please download the dataset and set the correct path\" \n",
    "\n",
    "makedirs(args)\n",
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else args.device)\n",
    "\n",
    "loader = data_loader(args)\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    unet = UNet(in_channels=Dataset.in_channels, out_channels=Dataset.out_channels)\n",
    "    state_dict = torch.load(args.weights, map_location=device)\n",
    "    unet.load_state_dict(state_dict)\n",
    "    unet.eval()\n",
    "    unet.to(device)\n",
    "\n",
    "    input_list = []\n",
    "    pred_list = []\n",
    "    true_list = []\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        x, y_true = data\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        y_pred = unet(x)\n",
    "        y_pred_np = y_pred.detach().cpu().numpy()\n",
    "        pred_list.extend([y_pred_np[s] for s in range(y_pred_np.shape[0])])\n",
    "\n",
    "        y_true_np = y_true.detach().cpu().numpy()\n",
    "        true_list.extend([y_true_np[s] for s in range(y_true_np.shape[0])])\n",
    "\n",
    "        x_np = x.detach().cpu().numpy()\n",
    "        input_list.extend([x_np[s] for s in range(x_np.shape[0])])\n",
    "\n",
    "volumes = postprocess_per_volume(\n",
    "    input_list,\n",
    "    pred_list,\n",
    "    true_list,\n",
    "    loader.dataset.patient_slice_index,\n",
    "    loader.dataset.patients,\n",
    ")\n",
    "\n",
    "dsc_dist = dsc_distribution(volumes)\n",
    "\n",
    "dsc_dist_plot = plot_dsc(dsc_dist)\n",
    "imsave(args.figure, dsc_dist_plot)\n",
    "\n",
    "for p in volumes:\n",
    "    x = volumes[p][0]\n",
    "    y_pred = volumes[p][1]\n",
    "    y_true = volumes[p][2]\n",
    "    for s in range(x.shape[0]):\n",
    "        image = gray2rgb(x[s, 1])  # channel 1 is for FLAIR\n",
    "        image = outline(image, y_pred[s, 0], color=[255, 0, 0])\n",
    "        image = outline(image, y_true[s, 0], color=[0, 255, 0])\n",
    "        filename = \"{}-{}.png\".format(p, str(s).zfill(2))\n",
    "        filepath = os.path.join(args.predictions, filename)\n",
    "        dirpath = os.path.dirname(filepath)\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "        imsave(filepath, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
