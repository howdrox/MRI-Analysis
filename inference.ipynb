{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the validation set with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T13:51:53.180424Z",
     "start_time": "2020-06-11T13:51:48.951064Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from medpy.filter.binary import largest_connected_component\n",
    "from skimage.io import imsave\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import BrainSegmentationDataset as Dataset\n",
    "from unet import UNet\n",
    "from utils import dsc, gray2rgb, outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T13:51:53.211553Z",
     "start_time": "2020-06-11T13:51:53.183003Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_loader(args):\n",
    "    dataset = Dataset(\n",
    "        images_dir=args.images,\n",
    "        subset=\"validation\",\n",
    "        image_size=args.image_size,\n",
    "        random_sampling=False,\n",
    "    )\n",
    "    loader = DataLoader(\n",
    "        dataset, batch_size=args.batch_size, drop_last=False, num_workers=0\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "def postprocess_per_volume(\n",
    "    input_list, pred_list, true_list, patient_slice_index, patients\n",
    "):\n",
    "    volumes = {}\n",
    "    num_slices = np.bincount([p[0] for p in patient_slice_index])\n",
    "    index = 0\n",
    "    for p in range(len(num_slices)):\n",
    "        volume_in = np.array(input_list[index : index + num_slices[p]])\n",
    "        volume_pred = np.round(\n",
    "            np.array(pred_list[index : index + num_slices[p]])\n",
    "        ).astype(int)\n",
    "        volume_pred = largest_connected_component(volume_pred)\n",
    "        volume_true = np.array(true_list[index : index + num_slices[p]])\n",
    "        volumes[patients[p]] = (volume_in, volume_pred, volume_true)\n",
    "        index += num_slices[p]\n",
    "    return volumes\n",
    "\n",
    "\n",
    "def dsc_distribution(volumes):\n",
    "    dsc_dict = {}\n",
    "    for p in volumes:\n",
    "        y_pred = volumes[p][1]\n",
    "        y_true = volumes[p][2]\n",
    "        dsc_dict[p] = dsc(y_pred, y_true, lcc=False)\n",
    "    return dsc_dict\n",
    "\n",
    "\n",
    "def plot_dsc(dsc_dist):\n",
    "    y_positions = np.arange(len(dsc_dist))\n",
    "    dsc_dist = sorted(dsc_dist.items(), key=lambda x: x[1])\n",
    "    values = [x[1] for x in dsc_dist]\n",
    "    labels = [x[0] for x in dsc_dist]\n",
    "    labels = [\"_\".join(l.split(\"_\")[1:-1]) for l in labels]\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    plt.barh(y_positions, values, align=\"center\", color=\"skyblue\")\n",
    "    plt.yticks(y_positions, labels)\n",
    "    plt.xticks(np.arange(0.0, 1.0, 0.1))\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.gca().axvline(np.mean(values), color=\"tomato\", linewidth=2)\n",
    "    plt.gca().axvline(np.median(values), color=\"forestgreen\", linewidth=2)\n",
    "    plt.xlabel(\"Dice coefficient\", fontsize=\"x-large\")\n",
    "    plt.gca().xaxis.grid(color=\"silver\", alpha=0.5, linestyle=\"--\", linewidth=1)\n",
    "    plt.tight_layout()\n",
    "    canvas.draw()\n",
    "    plt.close()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "    return np.frombuffer(s, np.uint8).reshape((height, width, 4))\n",
    "\n",
    "\n",
    "def makedirs(args):\n",
    "    os.makedirs(args.predictions, exist_ok=True)\n",
    "\n",
    "\n",
    "def plot_accuracy(acc_dist):\n",
    "    y_pos = np.arange(len(acc_dist))\n",
    "    items = sorted(acc_dist.items(), key=lambda x: x[1])\n",
    "    values = [v for _, v in items]\n",
    "    labels = [\"_\".join(k.split(\"_\")[1:-1]) for k, _ in items]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    plt.barh(y_pos, values, align=\"center\", color=\"lightgray\")\n",
    "    plt.yticks(y_pos, labels)\n",
    "    plt.xticks(np.arange(0.9, 1.0, 0.01))\n",
    "    plt.xlim([0.9, 1.0])\n",
    "    plt.axvline(np.mean(values), color=\"tomato\", linewidth=2)\n",
    "    plt.axvline(np.median(values), color=\"forestgreen\", linewidth=2)\n",
    "    plt.xlabel(\"Accuracy\", fontsize=\"x-large\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    canvas.draw()\n",
    "    plt.close()\n",
    "    s, (w, h) = canvas.print_to_buffer()\n",
    "    return np.frombuffer(s, np.uint8).reshape((h, w, 4))\n",
    "\n",
    "def acc_distribution(volumes):\n",
    "    acc_dist = {}\n",
    "    for p, (vol_in, vol_pred, vol_true) in volumes.items():\n",
    "        # vol_pred and vol_true are binary masks (0 or 1) after postprocess\n",
    "        # Flatten to 1D arrays\n",
    "        pred_flat = vol_pred.flatten()\n",
    "        true_flat = vol_true.flatten()\n",
    "\n",
    "        # Count TP, TN, FP, FN\n",
    "        tp = np.logical_and(pred_flat == 1, true_flat == 1).sum()\n",
    "        tn = np.logical_and(pred_flat == 0, true_flat == 0).sum()\n",
    "        fp = np.logical_and(pred_flat == 1, true_flat == 0).sum()\n",
    "        fn = np.logical_and(pred_flat == 0, true_flat == 1).sum()\n",
    "\n",
    "        # Avoid division by zero\n",
    "        total = tp + tn + fp + fn + 1e-8\n",
    "        acc_dist[p] = (tp + tn) / total\n",
    "    return acc_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    device = 'cuda:0'\n",
    "    batch_size = 32\n",
    "    weights = './weights/1-unet.pt'\n",
    "    images = './BrainMRI/kaggle_3m'\n",
    "    image_size = 256\n",
    "    predictions = './predictions'\n",
    "    dsc_figure = './report/img/validation_dsc_2.png'\n",
    "    accuracy_figure = './report/img/validation_accuracy_2.png'\n",
    "    logs = \"./logs\"\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T13:51:53.256508Z",
     "start_time": "2020-06-11T13:51:53.214026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading validation images...\n",
      "Load dataset from cache: .cache\\validation.pkl\n",
      "done creating validation dataset\n",
      "Patient kaggle_3m\\TCGA_HT_7616_19940813: Accuracy = 0.9929, DSC = 0.7638\n",
      "Patient kaggle_3m\\TCGA_CS_6668_20011025: Accuracy = 0.9859, DSC = 0.0000\n",
      "Patient kaggle_3m\\TCGA_CS_4944_20010208: Accuracy = 0.9932, DSC = 0.8842\n",
      "Patient kaggle_3m\\TCGA_HT_7879_19981009: Accuracy = 0.9986, DSC = 0.9086\n",
      "Patient kaggle_3m\\TCGA_DU_7014_19860618: Accuracy = 0.9966, DSC = 0.9002\n",
      "Patient kaggle_3m\\TCGA_DU_6408_19860521: Accuracy = 0.9969, DSC = 0.9386\n",
      "Patient kaggle_3m\\TCGA_DU_6404_19850629: Accuracy = 0.9992, DSC = 0.9346\n",
      "Patient kaggle_3m\\TCGA_DU_5851_19950428: Accuracy = 0.9989, DSC = 0.9271\n",
      "Patient kaggle_3m\\TCGA_CS_6667_20011105: Accuracy = 0.9990, DSC = 0.9294\n",
      "Patient kaggle_3m\\TCGA_HT_7692_19960724: Accuracy = 0.9994, DSC = 0.9063\n"
     ]
    }
   ],
   "source": [
    "assert osp.exists(args.images), \"Please download the dataset and set the correct path\" \n",
    "\n",
    "makedirs(args)\n",
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else args.device)\n",
    "\n",
    "loader = data_loader(args)\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    unet = UNet(in_channels=Dataset.in_channels, out_channels=Dataset.out_channels)\n",
    "    state_dict = torch.load(args.weights, map_location=device)\n",
    "    unet.load_state_dict(state_dict)\n",
    "    unet.eval()\n",
    "    unet.to(device)\n",
    "\n",
    "    input_list = []\n",
    "    pred_list = []\n",
    "    true_list = []\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        x, y_true = data\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        y_pred = unet(x)\n",
    "        y_pred_np = y_pred.detach().cpu().numpy()\n",
    "        pred_list.extend([y_pred_np[s] for s in range(y_pred_np.shape[0])])\n",
    "\n",
    "        y_true_np = y_true.detach().cpu().numpy()\n",
    "        true_list.extend([y_true_np[s] for s in range(y_true_np.shape[0])])\n",
    "\n",
    "        x_np = x.detach().cpu().numpy()\n",
    "        input_list.extend([x_np[s] for s in range(x_np.shape[0])])\n",
    "\n",
    "volumes = postprocess_per_volume(\n",
    "    input_list,\n",
    "    pred_list,\n",
    "    true_list,\n",
    "    loader.dataset.patient_slice_index,\n",
    "    loader.dataset.patients,\n",
    ")\n",
    "\n",
    "# DSC distribution\n",
    "dsc_dist = dsc_distribution(volumes)\n",
    "\n",
    "dsc_dist_plot = plot_dsc(dsc_dist)\n",
    "imsave(args.dsc_figure, dsc_dist_plot)\n",
    "\n",
    "# Accuracy distribution\n",
    "acc_dist = acc_distribution(volumes)\n",
    "\n",
    "acc_plot = plot_accuracy(acc_dist)\n",
    "imsave(args.accuracy_figure, acc_plot)\n",
    "\n",
    "for p in volumes:\n",
    "    acc = acc_dist[p]\n",
    "    dsc_value = dsc_dist[p]\n",
    "    print(f\"Patient {p}: Accuracy = {acc:.4f}, DSC = {dsc_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean DSC: 0.8093\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for p in volumes:\n",
    "    s += dsc_dist[p]\n",
    "print(f\"Mean DSC: {s / len(volumes):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in volumes:\n",
    "    x = volumes[p][0]\n",
    "    y_pred = volumes[p][1]\n",
    "    y_true = volumes[p][2]\n",
    "    for s in range(x.shape[0]):\n",
    "        image = gray2rgb(x[s, 1])  # channel 1 is for FLAIR\n",
    "        image = outline(image, y_pred[s, 0], color=[255, 0, 0])\n",
    "        image = outline(image, y_true[s, 0], color=[0, 255, 0])\n",
    "        filename = \"{}-{}.png\".format(p, str(s).zfill(2))\n",
    "        filepath = os.path.join(args.predictions, filename)\n",
    "        dirpath = os.path.dirname(filepath)\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "        imsave(filepath, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
